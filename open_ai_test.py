from langchain_openai import ChatOpenAI
from elasticsearch import Elasticsearch
import json
from config import OPEN_AI_API_KEY

# ğŸ”‘ API í‚¤
api_key = OPEN_AI_API_KEY

# ğŸ§‘ ì‚¬ìš©ì ì…ë ¥
user_input = "ë‚˜ëŠ” ê²½ì£¼ì—ì„œ ITì—…ì„ í•˜ê³ ìˆì–´, ë‚˜ì—ê²Œ í•„ìš”í•œ êµ­ê°€ ì§€ì›ì‚¬ì—…ì„ ì•Œë ¤ì¤˜."

# ğŸ” Elasticsearch ì—°ê²°
es = Elasticsearch("http://localhost:9200", verify_certs=False)
index_name = "support_projects"

# ğŸ“‹ Function Calling ìŠ¤í™ ì •ì˜
functions = [
    {
        "name": "get_support_info",
        "description": "êµ­ê°€ ì§€ì›ì‚¬ì—… ì •ë³´ë¥¼ ë°˜í™˜",
        "parameters": {
            "type": "object",
            "properties": {
                "ê³µê³ ëª…": {"type": "string"},
                "ì§€ì—­": {"type": "string"},
                "ê°€ëŠ¥ì—…ì¢…": {"type": "string"},
                "ìˆ˜ì¶œì‹¤ì ì—¬ë¶€": {"type": "string"},
                "ì§€ì›ê·œëª¨": {"type": "string"},
                "ëª¨ì§‘ê¸°ê°„": {"type": "string"},
                "í•µì‹¬í‚¤ì›Œë“œ": {
                    "type": "array",
                    "items": {"type": "string"},
                    "minItems": 1,
                    "maxItems": 5
                },
                "ê³µê³ ë‚´ìš©": {"type": "string"}
            },
            "required": ["ê³µê³ ëª…", "ì§€ì—­", "ê°€ëŠ¥ì—…ì¢…", "ìˆ˜ì¶œì‹¤ì ì—¬ë¶€", "ì§€ì›ê·œëª¨", "ëª¨ì§‘ê¸°ê°„", "í•µì‹¬í‚¤ì›Œë“œ", "ê³µê³ ë‚´ìš©"]
        }
    }
]

# ğŸ” Elasticsearch ê²€ìƒ‰ í•¨ìˆ˜
def search_support_projects(user_query: str, top_k: int = 3):
    query = {
        "query": {
            "match": {
                "text": user_query
            }
        }
    }
    res = es.search(index=index_name, body=query, size=top_k)
    return [hit["_source"]["text"] for hit in res["hits"]["hits"]]

# ğŸ§  LLM ê°ì²´ ìƒì„± (GPT + Function Call)
llm = ChatOpenAI(
    temperature=0,
    model_name='gpt-4o-mini',  # ë˜ëŠ” fine-tuned ëª¨ë¸
    openai_api_key=api_key,
    model_kwargs={
        "functions": functions,
        "function_call": {"name": "get_support_info"}
    }
)

# 1. ğŸ” ë¬¸ì„œ ê²€ìƒ‰
retrieved_docs = search_support_projects(user_input)

# 2. ğŸ”— ê²€ìƒ‰ ê²°ê³¼ë¥¼ contextë¡œ ì—°ê²°
context = "\n\n".join(retrieved_docs)

# 3. ğŸ¤– GPTì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
final_prompt = f"""
ì‚¬ìš©ì ì¡°ê±´: {user_input}

ë‹¤ìŒì€ ê²€ìƒ‰ëœ ì‹¤ì œ ì§€ì›ì‚¬ì—…ì…ë‹ˆë‹¤:

{context}

ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ì§€ì›ì‚¬ì—…ì„ ì‘ë‹µí•´ì¤˜.
ì§€ì—­ê³¼ ì—…ì¢…ì„ ì¤‘ì ìœ¼ë¡œ ì°¾ì•„ì¤˜
"""

# 4. ğŸš€ GPT í˜¸ì¶œ
response = llm.invoke(final_prompt)

# 5. ğŸ§¾ JSON â†’ ë³´ê¸° ì¢‹ì€ ìì—°ì–´ ë³€í™˜ í•¨ìˆ˜
def format_result(raw_json: str):
    parsed = json.loads(raw_json)
    return f"""
ğŸ“¢ ì§€ì›ì‚¬ì—… ì¶”ì²œ ì •ë³´

ğŸ“ ê³µê³ ëª…: {parsed['ê³µê³ ëª…']}
ğŸ“ ì§€ì—­: {parsed['ì§€ì—­']}
ğŸ­ ì—…ì¢…: {parsed['ê°€ëŠ¥ì—…ì¢…']}
ğŸš¢ ìˆ˜ì¶œ ì‹¤ì  ì—¬ë¶€: {parsed['ìˆ˜ì¶œì‹¤ì ì—¬ë¶€']}
ğŸ’° ì§€ì› ê·œëª¨: {parsed['ì§€ì›ê·œëª¨']}
ğŸ“† ëª¨ì§‘ ê¸°ê°„: {parsed['ëª¨ì§‘ê¸°ê°„']}
ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(parsed['í•µì‹¬í‚¤ì›Œë“œ'])}

ğŸ“„ ê³µê³  ë‚´ìš© ìš”ì•½:
{parsed['ê³µê³ ë‚´ìš©']}
"""

# 6. ğŸ“¤ ê²°ê³¼ ì¶œë ¥
arguments = response.additional_kwargs.get("function_call", {}).get("arguments")
if arguments:
    print(format_result(arguments))
else:
    print("â— í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
